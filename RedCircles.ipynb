{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6480ef",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad28b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import openpyxl\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dataDir = './archive/imagesMainWork'\n",
    "anotation_path = './archive/annotations'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8e984",
   "metadata": {},
   "source": [
    "# Function to Detect Red Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2750651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE\n",
    "\n",
    "def clahe(testImg):\n",
    "    testImg = cv2.cvtColor(testImg, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    h, s, v = testImg[:,:,0], testImg[:,:,1], testImg[:,:,2]\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit = 2.0, tileGridSize = (8, 8))\n",
    "\n",
    "    v = clahe.apply(v)\n",
    "\n",
    "    testImg = np.dstack((h, s, v))\n",
    "\n",
    "    testImg = cv2.cvtColor(testImg, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return testImg\n",
    "\n",
    "# REMOVE SHADOWS\n",
    "\n",
    "def removeShadows(testImg):\n",
    "    \n",
    "    rgb_planes = cv2.split(testImg)\n",
    "    result_norm_planes = []\n",
    "    for plane in rgb_planes:\n",
    "        dilated_img = cv2.dilate(plane, np.ones((7,7), np.uint8))\n",
    "        bg_img = cv2.medianBlur(dilated_img, 21)\n",
    "        diff_img = 255 - cv2.absdiff(plane, bg_img)\n",
    "        norm_img = cv2.normalize(diff_img,None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "        result_norm_planes.append(norm_img)\n",
    "\n",
    "    testImg = cv2.merge(result_norm_planes)\n",
    "    \n",
    "    return testImg\n",
    "\n",
    "#\n",
    "\n",
    "def redMask(testImg):\n",
    "    testImg = cv2.cvtColor(testImg, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # lower mask (0-10)\n",
    "    lower_red = np.array([0,50,50])\n",
    "    upper_red = np.array([10,255,255])\n",
    "    mask0 = cv2.inRange(testImg, lower_red, upper_red)\n",
    "\n",
    "    # upper mask (170-180)\n",
    "    lower_red = np.array([170,50,50])\n",
    "    upper_red = np.array([180,255,255])\n",
    "    mask1 = cv2.inRange(testImg, lower_red, upper_red)\n",
    "\n",
    "    # join my masks\n",
    "    mask = mask0+mask1\n",
    "\n",
    "    # set my output img to zero everywhere except my mask\n",
    "    testImgRed = ogImg.copy()\n",
    "    \n",
    "    testImgRed = cv2.cvtColor(testImgRed, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    testImgRed[np.where(mask==0)] = 0\n",
    "    \n",
    "    testImgRed = cv2.cvtColor(testImgRed, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    testImg = cv2.cvtColor(testImg, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return testImgRed\n",
    "\n",
    "\n",
    "# CLOSING\n",
    "\n",
    "def closing(testImgRed):\n",
    "    testImgRed = cv2.GaussianBlur(testImgRed, (11,11), 3)\n",
    "    testImgGray = cv2.cvtColor(testImgRed, cv2.COLOR_RGB2GRAY)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "    testImgGray = cv2.morphologyEx(testImgGray, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return testImgGray\n",
    "\n",
    "\n",
    "\n",
    "def findCircles(testImgRed):\n",
    "    # Use the Hough transform to detect circles in the image\n",
    "    circles = cv2.HoughCircles(testImgRed, cv2.HOUGH_GRADIENT, 1, testImgRed.shape[0] / 8, param1=50, param2=45, minRadius=0, maxRadius=0)\n",
    "    # If we have extracted a circle, draw an outline\n",
    "    # We only need to detect one circle here, since there will only be one reference object\n",
    "    return circles\n",
    "\n",
    "def detectCircles(ogImage):\n",
    "    finalImg = ogImg.copy()\n",
    "    testImg = ogImg.copy()\n",
    "            \n",
    "    for i in range(3):\n",
    "        testImg = ogImg.copy()\n",
    "        if i == 0:\n",
    "            noShadows = removeShadows(testImg)\n",
    "            redOnly = redMask(noShadows)\n",
    "            grayClosing = closing(redOnly)\n",
    "            circles = findCircles(grayClosing)        \n",
    "        if i == 1:\n",
    "            claheImg = clahe(testImg)\n",
    "            redOnly = redMask(claheImg)\n",
    "            grayClosing = closing(redOnly)\n",
    "            circles = findCircles(grayClosing)\n",
    "        if i == 2:\n",
    "            redOnly = redMask(testImg)\n",
    "            grayClosing = closing(redOnly)\n",
    "            circles = findCircles(grayClosing)\n",
    "        if circles is not None:\n",
    "            print(circles.shape[1])\n",
    "            return circles.shape[1]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4db31e",
   "metadata": {},
   "source": [
    "# Function to detect blue squares - Pre Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25308349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(img): \n",
    "\n",
    "    # remove noise\n",
    "    # Using a Median Filter\n",
    "    img_smoothed = cv2.medianBlur(img, 5)\n",
    "\n",
    "    return img_smoothed\n",
    "    # return img\n",
    "\n",
    "def contrastAdjust(img):\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    h, s, v = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "    v = clahe.apply(v)\n",
    "\n",
    "    img = np.dstack((h, s, v))\n",
    "\n",
    "    img_clean = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    return img_clean\n",
    "\n",
    "def removeShadows(img):\n",
    "    rgb_planes = cv2.split(img)\n",
    "    result_norm_planes = []\n",
    "    for plane in rgb_planes:\n",
    "        dilated_img = cv2.dilate(plane, np.ones((7, 7), np.uint8))\n",
    "        bg_img = cv2.medianBlur(dilated_img, 41)\n",
    "        diff_img = 255 - cv2.absdiff(plane, bg_img)\n",
    "        norm_img = cv2.normalize(\n",
    "            diff_img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "        result_norm_planes.append(norm_img)\n",
    "\n",
    "    img_clean = cv2.merge(result_norm_planes)\n",
    "\n",
    "    return img_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc582214",
   "metadata": {},
   "source": [
    "# Function to detect blue squares - Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CHANGE THIS\n",
    "\n",
    "def calcAngles(cnt_img, corners):\n",
    "    angles = []\n",
    "    \n",
    "    # Calculate euclidean distance between each corner\n",
    "    dist1 = int(math.sqrt(math.pow(corners[0] - corners[2], 2) +\n",
    "                       math.pow(corners[1] - corners[3], 2)))\n",
    "    dist2 = int(math.sqrt(math.pow(corners[2] - corners[4], 2) +\n",
    "                       math.pow(corners[3] - corners[5], 2)))\n",
    "    dist3 = int(math.sqrt(math.pow(corners[4] - corners[6], 2) +\n",
    "                   math.pow(corners[5] - corners[7], 2)))\n",
    "    dist4 = int(math.sqrt(math.pow(corners[6] - corners[0], 2) +\n",
    "                   math.pow(corners[7] - corners[1], 2)))\n",
    "\n",
    "    \n",
    "    max_radius = min([dist1, dist2, dist3, dist4])\n",
    "\n",
    "    for i in range(len(corners[:-1]), 2):\n",
    "        blank_img = np.zeros((len(cnt_img), len(cnt_img[0])), np.uint8)\n",
    "        cv2.circle(blank_img, (corners[i], corners[i + 1]),\n",
    "                  max_radius // 2, (255, 255, 255))\n",
    "        intersect_img = cv2.bitwise_and(cnt_img, blank_img)\n",
    "\n",
    "        intersect_pts = np.where(intersect_img > 1)\n",
    "\n",
    "        if(len(intersect_pts[0]) < 2 or len(intersect_pts[1]) < 2):\n",
    "            angles.append(0)\n",
    "            continue\n",
    "\n",
    "        vector1 = (intersect_pts[1][0] - corners[i],\n",
    "                   intersect_pts[0][0] - corners[i + 1])\n",
    "        vector2 = (intersect_pts[1][1] - corners[i],\n",
    "                   intersect_pts[0][1] - corners[i + 1])\n",
    "\n",
    "        scalar_p = vector1[0] * vector2[0] + vector1[1] * vector2[1]\n",
    "        norm1 = math.sqrt(math.pow(vector1[0], 2) + math.pow(vector1[1], 2))\n",
    "        norm2 = math.sqrt(math.pow(vector2[0], 2) + math.pow(vector2[1], 2))\n",
    "\n",
    "        angle = math.acos(scalar_p / (norm1 * norm2)) * 180 / math.pi\n",
    "        angles.append(angle)\n",
    "\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b166593",
   "metadata": {},
   "source": [
    "# Function to detect blue squares - Feature Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f313d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureRecognition(img): \n",
    "\n",
    "    # Segmentation to recognize colour blue\n",
    "    # Converts images from BGR to HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Bounds adjusted to identify shades of blue correspondent to traffic signs\n",
    "    lower_blue = np.array([100, 100, 80])\n",
    "    upper_blue = np.array([150, 255, 255])\n",
    "\n",
    "    # Here we are defining range of bluecolor in HSV\n",
    "    # This creates a mask of blue coloured\n",
    "    # objects found in the frame.\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # The bitwise and of the frame and mask is done so\n",
    "    # that only the blue coloured objects are highlighted\n",
    "    # and stored in res\n",
    "    res = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "\n",
    "    # Post-Segmentation smoothing \n",
    "    # res = smooth(res)  \n",
    "\n",
    "\n",
    "    # Contours on Resulting Image\n",
    "    gray_img = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Canny\n",
    "    canny = cv2.Canny(gray_img, 130, 255)\n",
    "\n",
    "    # Find Contours\n",
    "    # RETR_CCOMP: retrieves all of the contours and organizes them into a two-level hierarchy. At the top level, there are external boundaries of the components. \n",
    "    # At the second level, there are boundaries of the holes. If there is another contour inside a hole of a connected component, it is still put at the top level.\n",
    "    cnts = cv2.findContours(\n",
    "        canny, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "\n",
    "    for c in range(len(cnts)):\n",
    "        cnt_len = cv2.arcLength(cnts[c], True)\n",
    "\n",
    "        # Small contours will appear in green; can be commented and code will still work\n",
    "        if(cnt_len <= 70):\n",
    "            cv2.drawContours(img, [cnts[c]], 0, (0, 255, 0), 3)\n",
    "            continue \n",
    "\n",
    "        # Recognize most approximate CLOSED Poly-shape to contour to draw\n",
    "        approx_poly = cv2.approxPolyDP(\n",
    "            cnts[c], 0.03 * cv2.arcLength(cnts[c], True), True)\n",
    "\n",
    "        # Rectangle Recognition through Distance and Angle Analysis\n",
    "        ravel = approx_poly.ravel()\n",
    "        n_sides = len(approx_poly)\n",
    "        angle_cdt = False \n",
    "\n",
    "        # NÂº of Sides is 4 = Square/Rectangle\n",
    "        if(n_sides == 4): \n",
    "            angle_cdt = True \n",
    "\n",
    "            cnt_img = np.zeros((len(img), len(img[0])), np.uint8)\n",
    "            angles = calcAngles(cv2.drawContours(cnt_img, [approx_poly], -1, (255), 1), ravel)\n",
    "\n",
    "            for a in angles:\n",
    "                if(abs(a - 90) > 10):\n",
    "                    angle_cdt=False\n",
    "                    break\n",
    "            \n",
    "        if(angle_cdt):\n",
    "            img = cv2.drawContours(img, [approx_poly], -1, (0, 230, 255), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19821eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIFT & FLANN & RANSAC\n",
    "def featureDetectionAndMatching(img, train_list):\n",
    "\n",
    "    MIN_MATCH_COUNT = 5\n",
    "    count = 0\n",
    "    for img_path in train_list:\n",
    "\n",
    "        img_train = cv2.imread(img_path)\n",
    "\n",
    "        # Initiate SIFT detector\n",
    "        sift = cv2.SIFT_create()\n",
    "\n",
    "        \n",
    "        # find the keypoints & compute descriptors\n",
    "        kp, des = sift.detectAndCompute(img_train, None)\n",
    "        kp2, des2 = sift.detectAndCompute(img, None)\n",
    "\n",
    "\n",
    "        # create FLANN feature matcher\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "\n",
    "        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(des, des2, k=2)\n",
    "\n",
    "        # store all the good matches as per Lowe's ratio test.\n",
    "        good = []\n",
    "        for m, n in matches:\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                good.append(m)\n",
    "\n",
    "        if len(good) >= MIN_MATCH_COUNT:\n",
    "            src_pts = np.float32([kp[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "            dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "            matchesMask = mask.ravel().tolist()\n",
    "            h, w = img_train.shape[:2]\n",
    "            pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]\n",
    "                            ).reshape(-1, 1, 2)\n",
    "            if not M is None:\n",
    "                dst = cv2.perspectiveTransform(pts, M)\n",
    "                img = cv2.polylines(img, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "            else:   \n",
    "                continue\n",
    "        else:\n",
    "            matchesMask = None\n",
    "            continue\n",
    "\n",
    "        count+=1\n",
    "\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e9fe8",
   "metadata": {},
   "source": [
    "# Loop to analize the entire data set (download from kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33883dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# TODO: meter mais imagens de limite de velocidade recomendado\n",
    "train_set = ['./train-img/crossing.png', './train-img/crossing_1.png',\n",
    "             './train-img/passage_priority.png', './train-img/dead_end.png', './train-img/roads_limits.png', './train-img/via_reservada.png', './train-img/via_reservada_end.png', './train-img/info.png', './train-img/information-lane-end.png', './train-img/information-lane-start.png', './train-img/information-lanes.png', './train-img/information-motorway_end.png', './train-img/information-motorway.png', './train-img/information-one-way-traffic_end.png', './train-img/information-one-way-traffic.png', './train-img/information-parking.png', './train-img/information-speed-recommended_end.png', './train-img/information-speed-recommended.png', './train-img/information-tunnel_end.png', './train-img/information-tunnel.png', './train-img/information-two-way-traffic.png']\n",
    "\n",
    "\n",
    "onlyfiles = [f for f in listdir(dataDir) if isfile(join(dataDir, f))]\n",
    " \n",
    "workbook = openpyxl.load_workbook(\"RoadSigns.xlsx\")\n",
    " \n",
    "sheet = workbook.active\n",
    "# Start from the first cell.\n",
    "# Rows and columns are zero indexed.\n",
    "row_number = 2\n",
    "\n",
    "print(len(onlyfiles))\n",
    "# iterating through content list\n",
    "for item in onlyfiles :\n",
    "    \n",
    "    \n",
    "    ogImg = cv2.imread(os.path.join(dataDir, item))\n",
    "    \n",
    "    #img_clean = removeShadows(contrastAdjust(ogImg))\n",
    "    \n",
    "    #nrBlueSquares = featureDetectionAndMatching(img_clean, train_set)\n",
    "    \n",
    "    cv2.imshow(\"teste\",ogImg)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    ogImgRGB = cv2.cvtColor(ogImg, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    nrCircles = detectCircles(ogImgRGB)\n",
    "    \n",
    "    if nrCircles > 0:\n",
    "        sheet.cell(row = row_number, column = 3, value = \"speedlimit\")\n",
    "    else: \n",
    "        sheet.cell(row = row_number, column = 3, value = \"other\")\n",
    "    #sheet.cell(row = row_number, column = 7, value = nrBlueSquares)\n",
    "    \n",
    "\n",
    "    row_number += 1\n",
    "\n",
    "workbook.save(\"RoadSigns.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa8a6c2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843daa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red Circles Accuracy\n",
    "actual = sheet['B']\n",
    "detected = sheet['C']\n",
    "\n",
    "def mapping(cell):\n",
    "    return cell.value\n",
    "\n",
    "actual = list(map(mapping, actual[1:]))\n",
    "detected = list(map(mapping, detected[1:]))\n",
    "accuracy = round(accuracy_score(actual, detected) * 100)\n",
    "\n",
    "print(\"Accuracy for Red Circles: {}%\".format(accuracy))\n",
    "\n",
    "# # Blue Squares/Rectangles Accuracy\n",
    "# actual = sheet['D']\n",
    "# detected = sheet['G']\n",
    "\n",
    "# def mapping(cell):\n",
    "#     return cell.value\n",
    "\n",
    "# actual = list(map(mapping, actual[1:]))\n",
    "# detected = list(map(mapping, detected[1:]))\n",
    "\n",
    "# accuracy = round(accuracy_score(actual, detected) * 100)\n",
    "\n",
    "# print(\"Accuracy for Blue Squares/Rectangles: {}%\".format(accuracy))\n",
    "\n",
    "# # Stops Accuracy\n",
    "# actual = sheet['B']\n",
    "# detected = sheet['E']\n",
    "\n",
    "# def mapping(cell):\n",
    "#     return cell.value\n",
    "\n",
    "# actual = list(map(mapping, actual[1:]))\n",
    "# detected = list(map(mapping, detected[1:]))\n",
    "\n",
    "# accuracy = round(accuracy_score(actual, detected) * 100)\n",
    "\n",
    "# print(\"Accuracy for Stops: {}%\".format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289f9a1",
   "metadata": {},
   "source": [
    "# Run to generate the initial file \n",
    "## Filtered dataset information processed - 85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xlsxwriter module\n",
    "import xlsxwriter\n",
    "import xml.dom.minidom\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [\".\".join(f.split(\".\")[:-1]) for f in listdir(dataDir) if isfile(join(dataDir, f))]\n",
    " \n",
    "workbook = xlsxwriter.Workbook('RoadSigns.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "worksheet.write('A1', 'File Name')\n",
    "worksheet.write('B1', 'Type of Sign')\n",
    "worksheet.write('C1', 'Type of Sign Detected')\n",
    "# Start from the first cell.\n",
    "# Rows and columns are zero indexed.\n",
    "row = 1\n",
    "column = 0\n",
    "\n",
    " \n",
    "# iterating through content list\n",
    "for item in onlyfiles :\n",
    "    typeOfSign = \"\";\n",
    "    doc = xml.dom.minidom.parse(os.path.join(anotation_path,item + \".xml\"));\n",
    "    \n",
    "    signsNames = doc.getElementsByTagName(\"name\")\n",
    "    \n",
    "    for sign in signsNames:\n",
    "     if sign.childNodes[0].nodeValue == \"stop\":\n",
    "        typeOfSign = \"stop\";\n",
    "     elif sign.childNodes[0].nodeValue == \"speedlimit\":\n",
    "        typeOfSign = \"speedlimit\";\n",
    "     elif sign.childNodes[0].nodeValue == \"crosswalk\":\n",
    "        typeOfSign = \"crosswalk\";\n",
    "    \n",
    "    # write operation perform\n",
    "    if typeOfSign == \"speedlimit\":\n",
    "        worksheet.write(row, column, item)\n",
    "        worksheet.write(row, 1, typeOfSign)\n",
    "        # incrementing the value of row by one\n",
    "        # with each iterations.\n",
    "    else:\n",
    "        worksheet.write(row, column, item)\n",
    "        worksheet.write(row, 1, \"other\")\n",
    " \n",
    "    row += 1\n",
    "     \n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3e93f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
