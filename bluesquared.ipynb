{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLUE SQUARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./archive/images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(img): \n",
    "\n",
    "    # remove noise\n",
    "    # Using a Median Filter\n",
    "    img_smoothed = cv2.medianBlur(img, 5)\n",
    "\n",
    "    return img_smoothed\n",
    "\n",
    "def contrastAdjust(img):\n",
    "\n",
    "    # adjust contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "    # convert to YCrCb and apply CLAHE on Y component\n",
    "    img_YCrCb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # apply CLAHE on component Y\n",
    "    img_YCrCb[:, :, 0] = clahe.apply(img_YCrCb[:, :, 0])\n",
    "\n",
    "    img_clean = cv2.cvtColor(img_YCrCb, cv2.COLOR_YCrCb2BGR)\n",
    "    \n",
    "    return img_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CHANGE THIS\n",
    "\n",
    "def calcAngles(cnt_img, corners):\n",
    "    angles = []\n",
    "    \n",
    "    # Calculate euclidean distance between each corner\n",
    "    d1 = int(math.sqrt(math.pow(corners[0] - corners[2], 2) +\n",
    "                       math.pow(corners[1] - corners[3], 2)))\n",
    "    d2 = int(math.sqrt(math.pow(corners[2] - corners[4], 2) +\n",
    "                       math.pow(corners[3] - corners[5], 2)))\n",
    "    d3 = int(math.sqrt(math.pow(corners[4] - corners[6], 2) +\n",
    "                   math.pow(corners[5] - corners[7], 2)))\n",
    "    d4 = int(math.sqrt(math.pow(corners[6] - corners[0], 2) +\n",
    "                   math.pow(corners[7] - corners[1], 2)))\n",
    "\n",
    "    max_radius = min([d1, d2, d3, d4])\n",
    "\n",
    "    for k in range(len(corners) - 1):\n",
    "        if(k % 2 != 0):\n",
    "            continue\n",
    "\n",
    "        blank_img = np.zeros((len(cnt_img), len(cnt_img[0])), np.uint8)\n",
    "        cv2.circle(blank_img, (corners[k], corners[k + 1]),\n",
    "                  max_radius // 2, (255, 255, 255))\n",
    "        intersect_img = cv2.bitwise_and(cnt_img, blank_img)\n",
    "\n",
    "        intersect_pts = np.where(intersect_img > 1)\n",
    "\n",
    "        if(len(intersect_pts[0]) < 2 or len(intersect_pts[1]) < 2):\n",
    "            angles.append(0)\n",
    "            continue\n",
    "\n",
    "        vector1 = (intersect_pts[1][0] - corners[k],\n",
    "                   intersect_pts[0][0] - corners[k + 1])\n",
    "        vector2 = (intersect_pts[1][1] - corners[k],\n",
    "                   intersect_pts[0][1] - corners[k + 1])\n",
    "\n",
    "        scalar_p = vector1[0] * vector2[0] + vector1[1] * vector2[1]\n",
    "        norm1 = math.sqrt(math.pow(vector1[0], 2) + math.pow(vector1[1], 2))\n",
    "        norm2 = math.sqrt(math.pow(vector2[0], 2) + math.pow(vector2[1], 2))\n",
    "\n",
    "        angle = math.acos(scalar_p / (norm1 * norm2)) * 180 / math.pi\n",
    "        angles.append(angle)\n",
    "\n",
    "    return angles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features: blue rectangle\n",
    "\n",
    "def featureRecognition(img): \n",
    "\n",
    "    # blue segmentation\n",
    "    # Converts images from BGR to HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Bounds adjusted to identify shades of blue correspondent to traffic signs\n",
    "    lower_blue = np.array([105, 90, 90])\n",
    "    upper_blue = np.array([150, 255, 255])\n",
    "\n",
    "    # Here we are defining range of bluecolor in HSV\n",
    "    # This creates a mask of blue coloured\n",
    "    # objects found in the frame.\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # The bitwise and of the frame and mask is done so\n",
    "    # that only the blue coloured objects are highlighted\n",
    "    # and stored in res\n",
    "    res = cv2.bitwise_and(img, img, mask=mask)\n",
    "    cv2.imshow('original', img)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('res', res)\n",
    "\n",
    "\n",
    "\n",
    "    # TEST SEGMENTATION\n",
    "    cv2.waitKey()\n",
    "\n",
    "    # Destroys all of the HighGUI windows.\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    # Post-Segmentation smoothing\n",
    "    res = smooth(res)  \n",
    "\n",
    "\n",
    "    # Contours on Resulting Image\n",
    "    gray_img = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply Canny\n",
    "    canny = cv2.Canny(gray_img, 130, 255, 1)\n",
    "    \n",
    "    # Find Contours\n",
    "    # RETR_CCOMP: retrieves all of the contours and organizes them into a two-level hierarchy. At the top level, there are external boundaries of the components. \n",
    "    # At the second level, there are boundaries of the holes. If there is another contour inside a hole of a connected component, it is still put at the top level.\n",
    "    cnts = cv2.findContours(\n",
    "        canny, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "\n",
    "    for c in range(len(cnts)):\n",
    "        cnt_len = cv2.arcLength(cnts[c], True)\n",
    "\n",
    "        # FIXME: WHY??\n",
    "        if(cnt_len <= 70):\n",
    "            cv2.drawContours(img, [cnts[c]], 0, (0, 255, 0), 3)\n",
    "            continue \n",
    "\n",
    "\n",
    "        #  recognize most approximate Poly-shape to contour to draw\n",
    "        approx_poly = cv2.approxPolyDP(\n",
    "            cnts[c], 0.03 * cv2.arcLength(cnts[c], True), True)\n",
    "\n",
    "\n",
    "        # # FIXME: WHY?\n",
    "        # # calculate image area\n",
    "        # area = img.shape[0]*img.shape[1]\n",
    "        # # calculate ratio between image area and poly area\n",
    "        # ratio = int(cv2.contourArea(approx_poly)/float(area) * 100000.0)\n",
    "\n",
    "        # if ratio <= 65:\n",
    "        #     cv2.drawContours(img, [cnts[c]], 0, (0, 255, 0), 3)\n",
    "        #     continue\n",
    "\n",
    "        # if(len(approx_poly) <= 4):\n",
    "        #     cv2.drawContours(img, [cnts[c]], 0, (0, 255, 0), 3)\n",
    "\n",
    "\n",
    "\n",
    "        # rectangle recognition\n",
    "        ravel = approx_poly.ravel()\n",
    "        n_sides = len(approx_poly)\n",
    "        angle_cdt = False \n",
    "\n",
    "        # NÂº of Sides is 4 = Square/Rectangle\n",
    "        if(n_sides == 4): \n",
    "            angle_cdt = True \n",
    "\n",
    "            contour_only_img = np.zeros((len(img), len(img[0])), np.uint8)\n",
    "            angles = calcAngles(cv2.drawContours(contour_only_img, [approx_poly], -1, (255), 1), ravel)\n",
    "\n",
    "            for i in range(len(angles)):\n",
    "                if(abs(angles[i] - 90) > 10):\n",
    "                    angle_cdt=False\n",
    "                    break\n",
    "            \n",
    "        if(angle_cdt):\n",
    "            img = cv2.drawContours(img, [approx_poly], -1, (0, 255, 255), 3)\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"result\", img)\n",
    "\n",
    "\n",
    "\n",
    "    # TEST contours\n",
    "    cv2.waitKey()\n",
    "\n",
    "    # Destroys all of the HighGUI windows.\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(image_path, 'road318.png'))\n",
    "img_clean = contrastAdjust(smooth(img))\n",
    "featureRecognition(img_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b8aa58cbdd3fa7ee5838f11bebf8643e92d1255fc2cdda3e6cf742529abce79"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
